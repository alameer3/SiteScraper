#!/usr/bin/env python3
"""
ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Terminal Ù…Ø¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
"""
import sys
import json
from unified_extractor import UnifiedWebsiteExtractor

def print_usage():
    print("""
ğŸš€ Ø§Ø³ØªØ®Ø¯Ø§Ù… unified_extractor:

python run_extractor.py <URL> [Ù†ÙˆØ¹_Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬]

Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬:
- basic: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ø§Ø³ÙŠ Ø³Ø±ÙŠØ¹
- advanced: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ ØªØ­Ù„ÙŠÙ„
- complete: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø§Ù…Ù„ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª

Ø£Ù…Ø«Ù„Ø©:
python run_extractor.py https://example.com
python run_extractor.py https://httpbin.org basic
python run_extractor.py https://github.com advanced
""")

def main():
    if len(sys.argv) < 2:
        print_usage()
        return
    
    url = sys.argv[1]
    extraction_type = sys.argv[2] if len(sys.argv) > 2 else 'basic'
    
    print(f"ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ {extraction_type} Ù„Ù„Ù…ÙˆÙ‚Ø¹: {url}")
    
    extractor = UnifiedWebsiteExtractor()
    result = extractor.extract_website(url, extraction_type)
    
    print(f"\nâœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result['success']}")
    if result['success']:
        print(f"ğŸ“Š Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {result.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        print(f"ğŸ“ Ø§Ù„ÙˆØµÙ: {result.get('description', 'ØºÙŠØ± Ù…ØªØ§Ø­')[:100]}...")
        print(f"ğŸ”— Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {result.get('links_count', 0)}")
        print(f"ğŸ–¼ï¸ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±: {result.get('images_count', 0)}")
        print(f"ğŸ“„ Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {result.get('content_length', 0)} bytes")
    else:
        print(f"âŒ Ø®Ø·Ø£: {result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")

if __name__ == "__main__":
    main()